# The Options filed is neccessary when using a custom service account. It specifies the storage logging options for the build.
# Bucket to Store Build Logs

# GCP Native pipeline for CI/CD. Incorporates Sast Testing, through Sonar cube, SCAs through Snyk, DAST through OWASPZAP.
# >
# Throughout the pipeline, a raw uncompiled docker application is tested, built ans imaged, then sent to gcr and deployed on a kubernetes cluster.
# >>
# I learned alot regarding what each testing suite is checking for, and gained and awarness of the weaknesses in applications, from their arrangement of code; to their choice in images and dependancies.
# >>>
# The pain in this project comes from making multiple enviornments for each script to work in and making sure they are compatible with each other.
# >>>>
# Each script according to cloud build is in it's own independant world in which you need to mold to complete a single task.
# >>>>>
# In my mind simple is best when creating build scripts. Get the job done and get out.
# >>>>>>

# >>>>
# Logging Bucket for the build logs:
options:
  logging: GCS_ONLY
   
logsBucket: gs://caranthir-archive

# Neccessary substitions for the sonarcube script to work properly
# > >>
substitutions:
  _SONAR_PROJECT_KEY: "pipeline-test-2"
  _SONAR_ORGANIZATION: "gwenbleidd32"

# Clones content from repo that the trigger is aimed at
# > >>
steps:
- name: 'gcr.io/cloud-builders/git'
  entrypoint: 'sh'
  args:
  - '-c'
  - |
    git clone https://github.com/Gwenbleidd32/pipeline-test-2
    cd pipeline-test-2

# Step 2: Dummy Stored Volume- Attempted to pass gcloud shell enviornment through other scripts to no avail
# > >>>
- name: 'ubuntu'
  entrypoint: 'bash'
  args:
  - '-c'
  - |-
    apt-get update
    apt-get -y install wget default-jdk docker.io gnupg curl
    echo "deb [signed-by=/usr/share/keyrings/cloud.google.gpg] https://packages.cloud.google.com/apt cloud-sdk main" | tee -a /etc/apt/sources.list.d/google-cloud-sdk.list
    apt-get install -y apt-transport-https ca-certificates
    curl https://packages.cloud.google.com/apt/doc/apt-key.gpg | apt-key --keyring /usr/share/keyrings/cloud.google.gpg add -
    apt-get update && apt-get -y install google-cloud-sdk
  volumes:
  - name: 'shared-data'
    path: /mnt/shared-data

  # Step 3: Pytest Hybrid Code Testing and Coverage Report
  # > >>>
- name: 'python:3.8-slim'
  entrypoint: 'sh'
  volumes:
  - name: 'shared-data'
    path: /mnt/shared-data
  args:
  - '-c'
  - |
    # Gcloud installation for bucket push:
    apt-get update && apt-get install -y git wget default-jdk docker.io gnupg curl apt-transport-https ca-certificates
    echo "deb [signed-by=/usr/share/keyrings/cloud.google.gpg] https://packages.cloud.google.com/apt cloud-sdk main" | tee -a /etc/apt/sources.list.d/google-cloud-sdk.list
    curl https://packages.cloud.google.com/apt/doc/apt-key.gpg | apt-key --keyring /usr/share/keyrings/cloud.google.gpg add -
    apt-get update && apt-get -y install google-cloud-sdk

    # Preparing the environment for testing the code:
    cd /mnt/shared-data
    git clone https://github.com/Gwenbleidd32/pipeline-test-2 /mnt/shared-data/pipeline-test-2
    cd /mnt/shared-data/pipeline-test-2
    pip install --upgrade pip
    pip install -r requirements.txt
    pip install pytest pytest-cov

    # Test and push
    PYTHONPATH=$(pwd) pytest --cov=app --cov-report=xml:coverage.xml || { echo "pytest failed"; exit 1; }
    cat /mnt/shared-data/pipeline-test-2/coverage.xml
    /usr/bin/gsutil cp /mnt/shared-data/pipeline-test-2/coverage.xml gs://kaer-seren-archive/pie/coverage_report.xml

# Step 4: SonarQube Code Quality Scan SAST Testing
# > >>>
- name: 'sonarsource/sonar-scanner-cli'
  entrypoint: 'sh'
  secretEnv: ['SONAR_TOKEN']
  args:
  - '-c'
  - |
    sonar-scanner -X \
      -Dsonar.projectKey=${_SONAR_PROJECT_KEY} \
      -Dsonar.organization=${_SONAR_ORGANIZATION} \
      -Dsonar.sources=. \
      -Dsonar.host.url=https://sonarcloud.io \
      -Dsonar.login=$$SONAR_TOKEN \
      -Dsonar.python.coverage.reportPaths=/tmp/.scannerwork/coverage.xml \
      -Dsonar.python.xunit.reportPath=/tmp/.scannerwork/xunit-result-*.xml \
      -Dsonar.exclusions=**/__pycache__/**,**/*.pyc \
      -Dsonar.working.directory=/tmp/.scannerwork

# Step 5: Docker build and push to GCR
# > >>>
- name: 'gcr.io/cloud-builders/docker'
  args: ['build', '-t', 'gcr.io/$PROJECT_ID/cahir:v1.0.0', '.'] #builds the image

- name: 'gcr.io/cloud-builders/docker'
  args: ['push', 'gcr.io/$PROJECT_ID/cahir:v1.0.0'] # pushes the image to Google Container Registry


# Step 6: Snyk SCAs and Vulnerability Testing - Software Composition Analysis
# > >>>
- name: 'snyk/snyk-cli:docker'
  entrypoint: 'sh'
  secretEnv: ['SNYK_TOKEN']
  args:
  - '-c'
  - |
    snyk auth $$SNYK_TOKEN
    snyk test --docker gcr.io/$PROJECT_ID/cahir:v1.0.0 --file=Dockerfile || true


  # Step 7: OWASPZAP DAST Security Testing
  # > >>>
- name: 'ubuntu'
  entrypoint: 'bash'
  args:
  - '-c'
  - |-
    # Dependancies
    apt-get update
    apt-get -y install wget default-jdk docker.io gnupg curl
    echo "deb [signed-by=/usr/share/keyrings/cloud.google.gpg] https://packages.cloud.google.com/apt cloud-sdk main" | tee -a /etc/apt/sources.list.d/google-cloud-sdk.list
    apt-get install -y apt-transport-https ca-certificates
    curl https://packages.cloud.google.com/apt/doc/apt-key.gpg | apt-key --keyring /usr/share/keyrings/cloud.google.gpg add -
    apt-get update && apt-get -y install google-cloud-sdk

    # Zap configuration
    wget https://github.com/zaproxy/zaproxy/releases/download/v2.14.0/ZAP_2.14.0_Linux.tar.gz
    tar -xvf ZAP_2.14.0_Linux.tar.gz
    cd ZAP_2.14.0
    # Start the Docker container
    docker run -d --name cahir-app -p 5000:5000 gcr.io/$PROJECT_ID/cahir:v1.0.0
    sleep 30 # Ensure the app is fully started
    # Run ZAP scan against the running container
    ./zap.sh -cmd -quickurl http://localhost:5000 -quickprogress -quickout /workspace/zap_report.html
    # Copy the report to the cloud bucket
    /usr/bin/gsutil cp /workspace/zap_report.html gs://kaer-seren-archive/zap/zap_report.html

# Step 8: Kubernetes login
# > >>>
- name: 'gcr.io/cloud-builders/gcloud'
  args: ['container', 'clusters', 'get-credentials', 'atreides-war-fleet', '--zone', 'europe-west10', '--project', '$PROJECT_ID'] # Kubernetes login information

# Step 9: Kubernetes deployment and service - With rollout restart to update a live deployment
# > >>>
- name: 'gcr.io/cloud-builders/kubectl'
  entrypoint: 'sh'
  args:
  - '-c'
  - |
    kubectl apply -f k8s/deployment.yaml -v=8 && \
    kubectl apply -f k8s/service.yaml -v=8 && \
    kubectl rollout restart deployment/type-a && \ 
    kubectl get pods -v=8 && \
    kubectl get services -v=8

images:
- 'gcr.io/pooper-scooper/cahir:v1.0.0'

#Secrets
# > >>
availableSecrets:
  secretManager:
  - versionName: projects/pooper-scooper/secrets/SONAR_TOKEN/versions/latest
    env: 'SONAR_TOKEN'
  - versionName: projects/pooper-scooper/secrets/snyk-token/versions/latest
    env: 'SNYK_TOKEN'