#The Options filed is neccessary when using a custom service account. It specifies the storage logging options for the build.

options:
  logging: GCS_ONLY
   
logsBucket: gs://caranthir-archive

substitutions:
  _SONAR_PROJECT_KEY: "pipeline-test-2"
  _SONAR_ORGANIZATION: "gwenbleidd32"

#Clones content from repo that the trigger is aimed at
steps:
- name: 'gcr.io/cloud-builders/git'
  entrypoint: 'sh'
  args:
  - '-c'
  - |
    git clone https://github.com/Gwenbleidd32/pipeline-test-2
    cd pipeline-test-2

# Step 2: Set up the environment and install Google SDK and dependencies
- name: 'ubuntu'
  entrypoint: 'bash'
  args:
  - '-c'
  - |-
    apt-get update
    apt-get -y install wget default-jdk docker.io gnupg curl
    echo "deb [signed-by=/usr/share/keyrings/cloud.google.gpg] https://packages.cloud.google.com/apt cloud-sdk main" | tee -a /etc/apt/sources.list.d/google-cloud-sdk.list
    apt-get install -y apt-transport-https ca-certificates
    curl https://packages.cloud.google.com/apt/doc/apt-key.gpg | apt-key --keyring /usr/share/keyrings/cloud.google.gpg add -
    apt-get update && apt-get -y install google-cloud-sdk
  volumes:
  - name: 'shared-data'
    path: /mnt/shared-data

  # Step 3: Install dependencies and run tests
- name: 'python:3.8-slim'
  entrypoint: 'sh'
  volumes:
  - name: 'shared-data'
    path: /mnt/shared-data
  args:
  - '-c'
  - |
    apt-get update && apt-get install -y git
    cd /mnt/shared-data
    git clone https://github.com/Gwenbleidd32/pipeline-test-2 /mnt/shared-data/pipeline-test-2
    cd /mnt/shared-data/pipeline-test-2
    pip install --upgrade pip
    pip install -r requirements.txt
    pip install pytest pytest-cov
    pip list
    which pytest || { echo "pytest not found in PATH"; exit 1; }
    pytest --version || { echo "Unable to get pytest version"; exit 1; }
    # Debugging: List files to check structure
    echo "Directory structure:"
    ls -R
    mv coverage.xml /mnt/shared-data/coverage.xml
    /mnt/shared-data/google-cloud-sdk/bin/gsutil cp /mnt/shared-data/coverage.xml gs://kaer-seren-archive/pie/coverage_report.xml

#SonarCloud analysis step - Notice how the security scan is the first step :)
- name: 'sonarsource/sonar-scanner-cli'
  entrypoint: 'sh'
  secretEnv: ['SONAR_TOKEN']
  args:
  - '-c'
  - |
    sonar-scanner -X \
      -Dsonar.projectKey=${_SONAR_PROJECT_KEY} \
      -Dsonar.organization=${_SONAR_ORGANIZATION} \
      -Dsonar.sources=. \
      -Dsonar.host.url=https://sonarcloud.io \
      -Dsonar.login=$$SONAR_TOKEN \
      -Dsonar.python.coverage.reportPaths=/tmp/.scannerwork/coverage.xml \
      -Dsonar.python.xunit.reportPath=/tmp/.scannerwork/xunit-result-*.xml \
      -Dsonar.exclusions=**/__pycache__/**,**/*.pyc \
      -Dsonar.working.directory=/tmp/.scannerwork

#Docker build and push to GCR
- name: 'gcr.io/cloud-builders/docker'
  args: ['build', '-t', 'gcr.io/$PROJECT_ID/cahir:v1.0.0', '.'] #builds the image

- name: 'gcr.io/cloud-builders/docker'
  args: ['push', 'gcr.io/$PROJECT_ID/cahir:v1.0.0'] # pushes the image to Google Container Registry

# Step to run Snyk security scan on the built Docker image - Software composition analysis
- name: 'snyk/snyk-cli:docker'
  entrypoint: 'sh'
  secretEnv: ['SNYK_TOKEN']
  args:
  - '-c'
  - |
    snyk auth $$SNYK_TOKEN
    snyk test --docker gcr.io/$PROJECT_ID/cahir:v1.0.0 --file=Dockerfile || true


  # Run ZAP security scan on the Docker container Downloads Zap and it's Dependancies and installs SDK Shell to preform operations
- name: 'ubuntu'
  entrypoint: 'bash'
  volumes:
  - name: 'shared-data'
    path: /mnt/shared-data
  args:
  - '-c'
  - |-
    apt-get update
    apt-get -y install wget docker.io gsutil
    cd /mnt/shared-data
    wget https://github.com/zaproxy/zaproxy/releases/download/v2.14.0/ZAP_2.14.0_Linux.tar.gz
    tar -xvf ZAP_2.14.0_Linux.tar.gz
    cd ZAP_2.14.0
    # Start the Docker container
    docker run -d --name cahir-app -p 5000:5000 gcr.io/$PROJECT_ID/cahir:v1.0.0
    sleep 30 # Ensure the app is fully started
    # Run ZAP scan against the running container
    ./zap.sh -cmd -quickurl http://localhost:5000 -quickprogress -quickout /mnt/shared-data/zap_report.html
    # Copy the report to the cloud bucket
    /usr/bin/gsutil cp /mnt/shared-data/zap_report.html gs://kaer-seren-archive/zap/zap_report.html

#Kubernetes login information
- name: 'gcr.io/cloud-builders/gcloud'
  args: ['container', 'clusters', 'get-credentials', 'atreides-war-fleet', '--zone', 'europe-west10', '--project', '$PROJECT_ID'] # Kubernetes login information

#Kubernetes deployment and service - With rollout restart to update a live deployment
- name: 'gcr.io/cloud-builders/kubectl'
  entrypoint: 'sh'
  args:
  - '-c'
  - |
    kubectl apply -f k8s/deployment.yaml -v=8 && \
    kubectl apply -f k8s/service.yaml -v=8 && \
    kubectl rollout restart deployment/type-a && \ 
    kubectl get pods -v=8 && \
    kubectl get services -v=8

images:
- 'gcr.io/pooper-scooper/cahir:v1.0.0'

availableSecrets:
  secretManager:
  - versionName: projects/pooper-scooper/secrets/SONAR_TOKEN/versions/latest
    env: 'SONAR_TOKEN'
  - versionName: projects/pooper-scooper/secrets/snyk-token/versions/latest
    env: 'SNYK_TOKEN'

#Take notice how this file is ordered. first step to last step. The image is pulled, caontainerized, and pushed to GCR.
#Then the login of kubernetes is automated, and then a deployment and service is applied.
#Match you Service account with the right permissions for kubectl to make this work.
#Note, When using a Custom Service account you need specify a bucket to store your generated build logs Or else the build will fail.