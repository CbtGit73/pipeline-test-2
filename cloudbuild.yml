#The Options filed is neccessary when using a custom service account. It specifies the storage logging options for the build.

options:
  logging: GCS_ONLY
   
logsBucket: gs://caranthir-archive

substitutions:
  _SONAR_PROJECT_KEY: "pipeline-test-2"
  _SONAR_ORGANIZATION: "gwenbleidd32"

#Clones content from repo that the trigger is aimed at
steps:
- name: 'gcr.io/cloud-builders/git'
  entrypoint: 'sh'
  args:
  - '-c'
  - |
    git clone https://github.com/Gwenbleidd32/pipeline-test-2
    cd pipeline-test-2

  # Step 2: Install dependencies and run tests
- name: 'python:3.8-slim'
  entrypoint: 'sh'
  args:
  - '-c'
  - |
    cd pipeline-test-2
    echo "Upgrading pip..."
    pip install --upgrade pip
    echo "Installing requirements..."
    pip install -r requirements.txt
    echo "Installing pytest and pytest-cov..."
    pip install pytest pytest-cov
    echo "Installed packages:"
    pip list
    echo "Checking pytest path:"
    which pytest || { echo "pytest not found in PATH"; exit 1; }
    pytest --version || { echo "Unable to get pytest version"; exit 1; }
    echo "Running tests with pytest"
    echo "Current directory: $(pwd)"
    echo "Directory contents:"
    ls -la
    PYTHONPATH=$(pwd) pytest --cov=app --cov-report=xml || { echo "pytest failed"; exit 1; }
    mkdir -p /tmp/.scannerwork
    mv coverage.xml /tmp/.scannerwork/

  #Snyk security scan
- name: 'snyk/snyk-cli:docker'
  entrypoint: 'sh'
  secretEnv: ['SNYK_TOKEN']
  args:
  - '-c'
  - |
    snyk auth $$SNYK_TOKEN
    snyk test --file=requirements.txt || { echo "Snyk test failed"; exit 1; }    


#SonarCloud analysis step - Notice how the security scan is the first step :)
- name: 'sonarsource/sonar-scanner-cli'
  entrypoint: 'sh'
  secretEnv: ['SONAR_TOKEN']
  args:
  - '-c'
  - |
    sonar-scanner -X \
      -Dsonar.projectKey=${_SONAR_PROJECT_KEY} \
      -Dsonar.organization=${_SONAR_ORGANIZATION} \
      -Dsonar.sources=. \
      -Dsonar.host.url=https://sonarcloud.io \
      -Dsonar.login=$$SONAR_TOKEN \
      -Dsonar.python.coverage.reportPaths=/tmp/.scannerwork/coverage.xml \
      -Dsonar.python.xunit.reportPath=/tmp/.scannerwork/xunit-result-*.xml \
      -Dsonar.exclusions=**/__pycache__/**,**/*.pyc \
      -Dsonar.working.directory=/tmp/.scannerwork

#Docker build and push to GCR
- name: 'gcr.io/cloud-builders/docker'
  args: ['build', '-t', 'gcr.io/$PROJECT_ID/cahir:v1.0.0', '.'] #builds the image

- name: 'gcr.io/cloud-builders/docker'
  args: ['push', 'gcr.io/$PROJECT_ID/cahir:v1.0.0'] # pushes the image to Google Container Registry

#Kubernetes login information
- name: 'gcr.io/cloud-builders/gcloud'
  args: ['container', 'clusters', 'get-credentials', 'atreides-war-fleet', '--zone', 'europe-west10', '--project', '$PROJECT_ID'] # Kubernetes login information

#Kubernetes deployment and service - With rollout restart to update a live deployment
- name: 'gcr.io/cloud-builders/kubectl'
  entrypoint: 'sh'
  args:
  - '-c'
  - |
    kubectl apply -f k8s/deployment.yaml -v=8 && \
    kubectl apply -f k8s/service.yaml -v=8 && \
    kubectl rollout restart deployment/type-a && \ 
    kubectl get pods -v=8 && \
    kubectl get services -v=8

images:
- 'gcr.io/pooper-scooper/cahir:v1.0.0'

availableSecrets:
  secretManager:
  - versionName: projects/pooper-scooper/secrets/SONAR_TOKEN/versions/latest
    env: 'SONAR_TOKEN'
  - versionName: projects/pooper-scooper/secrets/snyk-token/versions/latest
    env: 'SNYK_TOKEN'
#Secrets are Painful
#- name: 'gcr.io/cloud-builders/kubectl'
#  args: ['apply', '-f', 'k8s/deployment.yaml'] #apply the deployment

#- name: 'gcr.io/cloud-builders/kubectl'
#  args: ['apply', '-f', 'k8s/service.yaml'] #apply the service

#  _COMMIT_SHA: 'latest'
#Take notice how this file is ordered. first step to last step. The image is pulled, caontainerized, and pushed to GCR.
#Then the login of kubernetes is automated, and then a deployment and service is applied.
#Match you Service account with the right permissions for kubectl to make this work.
#Note, When using a Custom Service account you need specify a bucket to store your generated build logs Or else the build will fail.